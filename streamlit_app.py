"""
DocPilot Streamlit UI - Interface web pour l'agent
Jour 5: Agent + CLI/mini-UI & Qualit√©
"""

import asyncio
import os
import sys
from pathlib import Path
from typing import Dict, Any
import streamlit as st
from datetime import datetime

# Add current directory to Python path for imports
sys.path.append(str(Path(__file__).parent))

from knowledge_copilot.agent import create_agent, SearchFilter


# Page configuration
st.set_page_config(
    page_title="DocPilot Assistant",
    page_icon="üöÅ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 1rem 0;
        background: linear-gradient(90deg, #1f77b4, #ff7f0e);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        font-size: 2.5rem;
        font-weight: bold;
    }
    
    .metric-card {
        background: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
        margin: 0.5rem 0;
    }
    
    .source-card {
        background: #ffffff;
        border: 1px solid #e0e0e0;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 0.5rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    .fallback-warning {
        background: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)


def initialize_session_state():
    """Initialize Streamlit session state"""
    if "conversation_history" not in st.session_state:
        st.session_state.conversation_history = []
    if "agent_config" not in st.session_state:
        st.session_state.agent_config = {
            "mcp_url": os.getenv("MCP_URL", "http://localhost:8000"),
            "llm_provider": "vertex",
            "project_id": os.getenv("PROJECT_ID"),
            "openai_api_key": os.getenv("OPENAI_API_KEY")
        }


def sidebar_configuration():
    """Sidebar for configuration and filters"""
    st.sidebar.markdown("## ‚öôÔ∏è Configuration")
    
    # Service configuration
    st.sidebar.subheader("Service MCP")
    mcp_url = st.sidebar.text_input(
        "URL du service MCP",
        value=st.session_state.agent_config["mcp_url"],
        help="URL de l'API MCP (ex: http://localhost:8000)"
    )
    
    # LLM configuration
    st.sidebar.subheader("Mod√®le de langage")
    llm_provider = st.sidebar.selectbox(
        "Fournisseur LLM",
        ["vertex", "openai"],
        index=0 if st.session_state.agent_config["llm_provider"] == "vertex" else 1
    )
    
    # Provider-specific settings
    if llm_provider == "vertex":
        project_id = st.sidebar.text_input(
            "Project ID Google Cloud",
            value=st.session_state.agent_config["project_id"] or "",
            help="Votre Project ID Google Cloud"
        )
        st.session_state.agent_config["project_id"] = project_id
    elif llm_provider == "openai":
        openai_key = st.sidebar.text_input(
            "Cl√© API OpenAI",
            value=st.session_state.agent_config["openai_api_key"] or "",
            type="password",
            help="Votre cl√© API OpenAI"
        )
        st.session_state.agent_config["openai_api_key"] = openai_key
    
    # Update session state
    st.session_state.agent_config.update({
        "mcp_url": mcp_url,
        "llm_provider": llm_provider
    })
    
    st.sidebar.markdown("---")
    
    # Search filters
    st.sidebar.subheader("üîç Filtres de recherche")
    
    source_filter = st.sidebar.selectbox(
        "Source",
        ["Toutes", "github", "gdrive"],
        help="Filtrer par source de documents"
    )
    
    repo_filter = st.sidebar.text_input(
        "Repository",
        placeholder="ex: mon-repo",
        help="Filtrer par repository GitHub sp√©cifique"
    )
    
    mime_filter = st.sidebar.selectbox(
        "Type de fichier",
        ["Tous", "text/markdown", "text/plain", "application/pdf", "text/html"],
        help="Filtrer par type MIME"
    )
    
    # Search parameters
    st.sidebar.subheader("üìä Param√®tres de recherche")
    
    top_k = st.sidebar.slider(
        "Nombre de chunks (top-k)",
        min_value=1,
        max_value=50,
        value=10,
        help="Nombre maximum de chunks √† r√©cup√©rer"
    )
    
    similarity_threshold = st.sidebar.slider(
        "Seuil de similarit√©",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.05,
        help="Seuil minimum de similarit√©"
    )
    
    # Create filter object
    filters = SearchFilter(
        source=source_filter if source_filter != "Toutes" else None,
        repo=repo_filter if repo_filter else None,
        mime=mime_filter if mime_filter != "Tous" else None,
        top_k=top_k,
        similarity_threshold=similarity_threshold
    )
    
    return filters


async def process_question_async(question: str, filters: SearchFilter) -> Dict[str, Any]:
    """Process question asynchronously"""
    try:
        # Create agent
        agent = create_agent(
            mcp_url=st.session_state.agent_config["mcp_url"],
            llm_provider=st.session_state.agent_config["llm_provider"],
            project_id=st.session_state.agent_config["project_id"],
            openai_api_key=st.session_state.agent_config["openai_api_key"]
        )
        
        # Process question
        response = await agent.ask(question, filters)
        
        # Close agent
        await agent.close()
        
        return {
            "success": True,
            "response": response,
            "error": None
        }
        
    except Exception as e:
        return {
            "success": False,
            "response": None,
            "error": str(e)
        }


def display_response(response, filters: SearchFilter):
    """Display agent response with rich formatting"""
    
    # Response metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <h4>‚è±Ô∏è Temps de r√©ponse</h4>
            <h2>{response.response_time:.3f}s</h2>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="metric-card">
            <h4>üìÑ Chunks analys√©s</h4>
            <h2>{response.chunks_scanned}</h2>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div class="metric-card">
            <h4>üéØ Top-k demand√©</h4>
            <h2>{filters.top_k}</h2>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        fallback_color = "#ff7f0e" if response.fallback_used else "#2ca02c"
        fallback_text = "Oui" if response.fallback_used else "Non"
        st.markdown(f"""
        <div class="metric-card">
            <h4>‚ö†Ô∏è Fallback</h4>
            <h2 style="color: {fallback_color}">{fallback_text}</h2>
        </div>
        """, unsafe_allow_html=True)
    
    # Fallback warning
    if response.fallback_used:
        st.markdown("""
        <div class="fallback-warning">
            <h4>‚ö†Ô∏è Information limit√©e</h4>
            <p>L'assistant n'a pas trouv√© suffisamment d'informations pertinentes dans la documentation pour r√©pondre de mani√®re compl√®te √† votre question.</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Main response
    st.markdown("### üí¨ R√©ponse")
    st.markdown(response.answer)
    
    # Sources
    if response.sources:
        st.markdown("### üìö Sources")
        
        for i, source in enumerate(response.sources):
            with st.expander(f"üìÑ {source['title'][:80]}... (Similarit√©: {source['similarity_score']:.3f})"):
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    st.markdown(f"**Titre:** {source['title']}")
                    st.markdown(f"**URI:** `{source['uri']}`")
                    if source['repo']:
                        st.markdown(f"**Repository:** `{source['repo']}`")
                    if source['path']:
                        st.markdown(f"**Chemin:** `{source['path']}`")
                
                with col2:
                    st.markdown(f"**Source:** `{source['source']}`")
                    st.markdown(f"**Type MIME:** `{source['mime']}`")
                    st.markdown(f"**Similarit√©:** `{source['similarity_score']:.3f}`")
                    st.markdown(f"**Chunk ID:** `{source['chunk_id']}`")
    
    # Technical details
    with st.expander("üîß D√©tails techniques"):
        st.json({
            "trace_id": response.trace_id,
            "response_time": response.response_time,
            "chunks_scanned": response.chunks_scanned,
            "fallback_used": response.fallback_used,
            "filters": {
                "source": filters.source,
                "repo": filters.repo,
                "mime": filters.mime,
                "top_k": filters.top_k,
                "similarity_threshold": filters.similarity_threshold
            }
        })


def display_conversation_history():
    """Display conversation history"""
    if st.session_state.conversation_history:
        st.markdown("### üìú Historique des conversations")
        
        for i, entry in enumerate(reversed(st.session_state.conversation_history[-5:])):  # Last 5
            with st.expander(f"üí¨ {entry['question'][:50]}... ({entry['timestamp']})"):
                st.markdown(f"**Question:** {entry['question']}")
                st.markdown(f"**R√©ponse:** {entry['answer']}")
                st.markdown(f"**Sources:** {len(entry['sources'])} documents")
                st.markdown(f"**Temps:** {entry['response_time']:.3f}s")


async def health_check_async():
    """Check system health"""
    try:
        agent = create_agent(
            mcp_url=st.session_state.agent_config["mcp_url"],
            llm_provider="vertex",  # Use vertex by default for health check
            project_id=st.session_state.agent_config["project_id"] or os.getenv("PROJECT_ID", "dummy")
        )
        
        health = await agent.health_check()
        await agent.close()
        return health
        
    except Exception as e:
        return {"status": "unhealthy", "error": str(e)}


def main():
    """Main Streamlit application"""
    
    # Initialize session state
    initialize_session_state()
    
    # Header
    st.markdown('<h1 class="main-header">üöÅ DocPilot Assistant</h1>', unsafe_allow_html=True)
    st.markdown("*Assistant conversationnel pour votre documentation GitHub et Google Drive*")
    
    # Sidebar configuration
    filters = sidebar_configuration()
    
    # Health check section
    with st.sidebar:
        st.markdown("---")
        st.subheader("üè• √âtat du syst√®me")
        
        if st.button("üîÑ V√©rifier l'√©tat"):
            with st.spinner("V√©rification..."):
                health = asyncio.run(health_check_async())
                
                if health["status"] == "healthy":
                    st.success("‚úÖ Syst√®me op√©rationnel")
                else:
                    st.error(f"‚ùå Probl√®me d√©tect√©: {health.get('error', 'Erreur inconnue')}")
    
    # Main interface
    col1, col2 = st.columns([3, 1])
    
    with col1:
        # Question input
        st.markdown("### üí≠ Posez votre question")
        question = st.text_area(
            "Question",
            placeholder="Exemple: Comment d√©ployer une application sur Cloud Run ?",
            height=100,
            label_visibility="collapsed"
        )
        
        # Action buttons
        col_ask, col_clear = st.columns([1, 1])
        
        with col_ask:
            ask_button = st.button("üöÄ Poser la question", type="primary", use_container_width=True)
        
        with col_clear:
            if st.button("üóëÔ∏è Effacer l'historique", use_container_width=True):
                st.session_state.conversation_history = []
                st.success("Historique effac√©!")
                st.rerun()
    
    with col2:
        # Example questions
        st.markdown("### üí° Questions d'exemple")
        example_questions = [
            "Comment packager un mod√®le pour Cloud Run ?",
            "Configuration Docker pour Python",
            "API endpoints disponibles",
            "Installation des d√©pendances",
            "D√©ploiement avec CI/CD"
        ]
        
        for eq in example_questions:
            if st.button(f"üí¨ {eq[:30]}...", key=f"example_{hash(eq)}", use_container_width=True):
                question = eq
                ask_button = True
    
    # Process question
    if ask_button and question.strip():
        with st.spinner("ü§î Traitement de votre question..."):
            # Process question
            result = asyncio.run(process_question_async(question, filters))
            
            if result["success"]:
                response = result["response"]
                
                # Display response
                st.markdown("---")
                display_response(response, filters)
                
                # Add to conversation history
                st.session_state.conversation_history.append({
                    "question": question,
                    "answer": response.answer,
                    "sources": response.sources,
                    "response_time": response.response_time,
                    "timestamp": datetime.now().strftime("%H:%M:%S"),
                    "trace_id": response.trace_id
                })
                
            else:
                st.error(f"‚ùå Erreur: {result['error']}")
    
    elif ask_button:
        st.warning("‚ö†Ô∏è Veuillez saisir une question.")
    
    # Conversation history
    if st.session_state.conversation_history:
        st.markdown("---")
        display_conversation_history()
    
    # Footer
    st.markdown("---")
    st.markdown(
        """
        <div style="text-align: center; color: #666; padding: 1rem;">
        DocPilot v1.0 - Assistant RAG avec Vertex AI et pgvector<br>
        üîó <a href="https://github.com" target="_blank">GitHub</a> | 
        üìß <a href="mailto:support@docpilot.ai">Support</a> |
        üìñ <a href="/docs" target="_blank">Documentation</a>
        </div>
        """,
        unsafe_allow_html=True
    )


if __name__ == "__main__":
    main()